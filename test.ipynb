{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5083fef",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_unstructured import UnstructuredLoader\n",
    "\n",
    "file_path = \"0.LangChain技术生态介绍.pdf\"\n",
    "\n",
    "loader_local = UnstructuredLoader(\n",
    "    file_path=file_path,\n",
    "    strategy=\"hi_res\",              # 高分辨率模式，支持复杂文档\n",
    "    infer_table_structure=True,     # 自动解析表格结构\n",
    "    ocr_languages=\"chi_sim+eng\",    # 支持中英文 OCR\n",
    "    ocr_engine=\"paddleocr\"          # 指定 PaddleOCR 作为 OCR 引擎\n",
    ")\n",
    "\n",
    "docs_local = []\n",
    "for doc in loader_local.lazy_load():\n",
    "    docs_local.append(doc)\n",
    "    \n",
    "docs_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827d5ff1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import fitz\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def plot_pdf_with_boxes(pdf_page, segments):\n",
    "    pix = pdf_page.get_pixmap()\n",
    "    pil_image = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "    ax.imshow(pil_image)\n",
    "    categories = set()\n",
    "    category_to_color = {\n",
    "        \"Title\": \"orchid\",\n",
    "        \"Image\": \"forestgreen\",\n",
    "        \"Table\": \"tomato\",\n",
    "    }\n",
    "    for segment in segments:\n",
    "        points = segment[\"coordinates\"][\"points\"]\n",
    "        layout_width = segment[\"coordinates\"][\"layout_width\"]\n",
    "        layout_height = segment[\"coordinates\"][\"layout_height\"]\n",
    "        scaled_points = [\n",
    "            (x * pix.width / layout_width, y * pix.height / layout_height)\n",
    "            for x, y in points\n",
    "        ]\n",
    "        box_color = category_to_color.get(segment[\"category\"], \"deepskyblue\")\n",
    "        categories.add(segment[\"category\"])\n",
    "        rect = patches.Polygon(\n",
    "            scaled_points, linewidth=1, edgecolor=box_color, facecolor=\"none\"\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    # Make legend\n",
    "    legend_handles = [patches.Patch(color=\"deepskyblue\", label=\"Text\")]\n",
    "    for category in [\"Title\", \"Image\", \"Table\"]:\n",
    "        if category in categories:\n",
    "            legend_handles.append(\n",
    "                patches.Patch(color=category_to_color[category], label=category)\n",
    "            )\n",
    "    ax.axis(\"off\")\n",
    "    ax.legend(handles=legend_handles, loc=\"upper right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def render_page(doc_list: list, page_number: int, print_text=True) -> None:\n",
    "    pdf_page = fitz.open(file_path).load_page(page_number - 1)\n",
    "    page_docs = [\n",
    "        doc for doc in doc_list if doc.metadata.get(\"page_number\") == page_number\n",
    "    ]\n",
    "    segments = [doc.metadata for doc in page_docs]\n",
    "    plot_pdf_with_boxes(pdf_page, segments)\n",
    "    if print_text:\n",
    "        for doc in page_docs:\n",
    "            print(f\"{doc.page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc7e43a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "render_page(docs_local, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e23f4eb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "pdf_path = \"0.LangChain技术生态介绍.pdf\"\n",
    "output_dir = \"pdf_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Step 1: 提取文本/结构化内容\n",
    "elements = partition_pdf(\n",
    "    filename=pdf_path,\n",
    "    infer_table_structure=True,   # 开启表格结构检测\n",
    "    strategy=\"hi_res\",            # 高分辨率 OCR，适合复杂表格\n",
    "    ocr_languages=\"chi_sim+eng\",  # 中英文混合识别\n",
    "    ocr_engine=\"paddleocr\"        # 指定 PaddleOCR 引擎\n",
    ")\n",
    "\n",
    "# Step 2: 提取图片并保存\n",
    "doc = fitz.open(pdf_path)\n",
    "image_map = {}  # 映射 page_num -> list of image paths\n",
    "\n",
    "for page_num, page in enumerate(doc, start=1):\n",
    "    image_map[page_num] = []\n",
    "    for img_index, img in enumerate(page.get_images(full=True), start=1):\n",
    "        xref = img[0]\n",
    "        pix = fitz.Pixmap(doc, xref)\n",
    "        img_path = os.path.join(output_dir, f\"page{page_num}_img{img_index}.png\")\n",
    "        if pix.n < 5:  # RGB / Gray\n",
    "            pix.save(img_path)\n",
    "        else:  # CMYK 转 RGB\n",
    "            pix = fitz.Pixmap(fitz.csRGB, pix)\n",
    "            pix.save(img_path)\n",
    "        image_map[page_num].append(img_path)\n",
    "        \n",
    "# Step 3: 转换为 Markdown\n",
    "md_lines = []\n",
    "inserted_images = set()  # 用来记录已经插入过的图片，避免重复\n",
    "\n",
    "for el in elements:\n",
    "    cat = el.category\n",
    "    text = el.text\n",
    "    page_num = el.metadata.page_number\n",
    "\n",
    "    if cat == \"Title\" and text.strip().startswith(\"- \"):\n",
    "        md_lines.append(text + \"\\n\")\n",
    "    elif cat == \"Title\":\n",
    "        md_lines.append(f\"# {text}\\n\")\n",
    "    elif cat in [\"Header\", \"Subheader\"]:\n",
    "        md_lines.append(f\"## {text}\\n\")\n",
    "    elif cat == \"Table\":\n",
    "        if hasattr(el.metadata, \"text_as_html\") and el.metadata.text_as_html:\n",
    "            from html2text import html2text\n",
    "            md_lines.append(html2text(el.metadata.text_as_html) + \"\\n\")\n",
    "        else:\n",
    "            md_lines.append(el.text + \"\\n\")\n",
    "    elif cat == \"Image\":\n",
    "        # 避免重复插入：只插入当前图片对应的文件\n",
    "        for img_path in image_map.get(page_num, []):\n",
    "            if img_path not in inserted_images:\n",
    "                md_lines.append(f\"![Image](./{img_path})\\n\")\n",
    "                inserted_images.add(img_path)\n",
    "    else:\n",
    "        md_lines.append(text + \"\\n\")\n",
    "\n",
    "# Step 4: 写入 Markdown 文件\n",
    "output_md = \"output.md\"\n",
    "with open(output_md, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(md_lines))\n",
    "\n",
    "print(f\"✅ 转换完成，已生成 {output_md} 和 {output_dir}/ 图片文件夹\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d49c364",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "pdf_path = \"MCP实战课件【合集】.pdf\"\n",
    "output_dir = \"pdf_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Step 1: 提取文本/结构化内容\n",
    "elements = partition_pdf(\n",
    "    filename=pdf_path,\n",
    "    infer_table_structure=True,   # 开启表格结构检测\n",
    "    strategy=\"hi_res\",            # 高分辨率 OCR，适合复杂表格\n",
    "    ocr_languages=\"chi_sim+eng\",  # 中英文混合识别\n",
    "    ocr_engine=\"paddleocr\"        # 指定 PaddleOCR 引擎\n",
    ")\n",
    "\n",
    "# Step 2: 提取图片并保存\n",
    "doc = fitz.open(pdf_path)\n",
    "image_map = {}  # 映射 page_num -> list of image paths\n",
    "\n",
    "for page_num, page in enumerate(doc, start=1):\n",
    "    image_map[page_num] = []\n",
    "    for img_index, img in enumerate(page.get_images(full=True), start=1):\n",
    "        xref = img[0]\n",
    "        pix = fitz.Pixmap(doc, xref)\n",
    "        img_path = os.path.join(output_dir, f\"page{page_num}_img{img_index}.png\")\n",
    "        if pix.n < 5:  # RGB / Gray\n",
    "            pix.save(img_path)\n",
    "        else:  # CMYK 转 RGB\n",
    "            pix = fitz.Pixmap(fitz.csRGB, pix)\n",
    "            pix.save(img_path)\n",
    "        image_map[page_num].append(img_path)\n",
    "# Step 3: 转换为 Markdown\n",
    "md_lines = []\n",
    "inserted_images = set()  # 用来记录已经插入过的图片，避免重复\n",
    "\n",
    "for el in elements:\n",
    "    cat = el.category\n",
    "    text = el.text\n",
    "    page_num = el.metadata.page_number\n",
    "\n",
    "    if cat == \"Title\" and text.strip().startswith(\"- \"):\n",
    "        md_lines.append(text + \"\\n\")\n",
    "    elif cat == \"Title\":\n",
    "        md_lines.append(f\"# {text}\\n\")\n",
    "    elif cat in [\"Header\", \"Subheader\"]:\n",
    "        md_lines.append(f\"## {text}\\n\")\n",
    "    elif cat == \"Table\":\n",
    "        if hasattr(el.metadata, \"text_as_html\") and el.metadata.text_as_html:\n",
    "            from html2text import html2text\n",
    "            md_lines.append(html2text(el.metadata.text_as_html) + \"\\n\")\n",
    "        else:\n",
    "            md_lines.append(el.text + \"\\n\")\n",
    "    elif cat == \"Image\":\n",
    "        # 避免重复插入：只插入当前图片对应的文件\n",
    "        for img_path in image_map.get(page_num, []):\n",
    "            if img_path not in inserted_images:\n",
    "                md_lines.append(f\"![Image](./{img_path})\\n\")\n",
    "                inserted_images.add(img_path)\n",
    "    else:\n",
    "        md_lines.append(text + \"\\n\")\n",
    "\n",
    "# Step 4: 写入 Markdown 文件\n",
    "output_md = \"output.md\"\n",
    "with open(output_md, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(md_lines))\n",
    "\n",
    "print(f\"✅ 转换完成，已生成 {output_md} 和 {output_dir}/ 图片文件夹\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81513763",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "OPENAI_EMBEDDING_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_EMBEDDING_BASE_URL = \"https://ai.devtool.tech/proxy/v1\"\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embed = OpenAIEmbeddings(\n",
    "    api_key=OPENAI_EMBEDDING_API_KEY,\n",
    "    base_url=OPENAI_EMBEDDING_BASE_URL,\n",
    "    model=\"text-embedding-3-small\" \n",
    ")\n",
    "\n",
    "# ! pip install langchain-text-splitters faiss-cpu --index-url https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "\n",
    "file_path = \"MCP实战课件【合集】.md\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    md_content = f.read()\n",
    "    \n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\")\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "md_header_splits = markdown_splitter.split_text(md_content)\n",
    "\n",
    "vector_store = FAISS.from_documents(md_header_splits, embedding=embed)\n",
    "vector_store.save_local(\"telco_customer_churn_analytics_handbook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6e4801",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import asyncio\n",
    "from typing import Literal\n",
    "from dotenv import load_dotenv \n",
    "load_dotenv(override=True)\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# LLM & Embeddings\n",
    "# ---------------------------------------------------------------------------\n",
    "MODEL_NAME = \"deepseek-chat\"\n",
    "model = init_chat_model(model=MODEL_NAME, model_provider=\"deepseek\", temperature=0)\n",
    "grader_model = init_chat_model(model=MODEL_NAME, model_provider=\"deepseek\", temperature=0)\n",
    "\n",
    "embed = OpenAIEmbeddings(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=\"https://ai.devtool.tech/proxy/v1\",\n",
    "    model=\"text-embedding-3-small\",\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Vector store & Retriever tool\n",
    "# ---------------------------------------------------------------------------\n",
    "VS_PATH = \"mcp_course_materials_db\"\n",
    "\n",
    "vector_store = FAISS.load_local(\n",
    "    folder_path=VS_PATH,\n",
    "    embeddings=embed,\n",
    "    allow_dangerous_deserialization=True,\n",
    ")\n",
    "retriever_tool = create_retriever_tool(\n",
    "    vector_store.as_retriever(search_kwargs={\"k\": 3}),\n",
    "    name=\"retrieve_mcp_course\",\n",
    "    description=\"Search and return relevant sections from the mcp course materials.\",\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Prompts\n",
    "# ---------------------------------------------------------------------------\n",
    "SYSTEM_INSTRUCTION = (\n",
    "    \"You are an MCP technical training assistant. 'MCP' refers to **Model Context Protocol**, \"\n",
    "    \"an open framework for enabling LLMs to call external tools. Do NOT confuse it with Microsoft Certified Professional.\\n\"\n",
    "    \"Answer ONLY questions related to the MCP practical course content, including tool invocation, streaming, LangGraph, API design, etc. \"\n",
    "    \"If the user question is NOT related to the course, reply: '我不能回答与 MCP 技术实战公开课无关的问题。' \"\n",
    "    \"You may call the provided tool `retriever_tool` when additional context is required.\"\n",
    ")\n",
    "\n",
    "GRADE_PROMPT = (\n",
    "    \"You are a grader assessing relevance of a retrieved document to a user question.\\n\"\n",
    "    \"Retrieved document:\\n{context}\\n\\nUser question: {question}\\n\"\n",
    "    \"Return 'yes' if relevant, otherwise 'no'.\"\n",
    ")\n",
    "\n",
    "REWRITE_PROMPT = (\n",
    "    \"You are rewriting user questions to make them more relevant to the MCP technical practical course.\\n\"\n",
    "    \"Note: In this context, **MCP stands for Model Context Protocol**, an open framework for enabling large language models to use external tools and structured APIs.\\n\"\n",
    "    \"Do NOT interpret MCP as Microsoft Certified Professional.\\n\"\n",
    "    \"Your job is to refine or clarify the user's question to make it better aligned with key concepts from the Model Context Protocol course, such as tool invocation, tool registration, streaming APIs, LangGraph workflows, etc.\\n\\n\"\n",
    "    \"Original question:\\n{question}\\nImproved question:\"\n",
    ")\n",
    "\n",
    "ANSWER_PROMPT = (\n",
    "    \"You are an assistant for answering questions related to the MCP technical practical course. \"\n",
    "    \"Use the provided context to answer the question as completely and accurately as possible. \"\n",
    "    \"Whenever relevant, include examples, code blocks, or image references that appear in the source material. \"\n",
    "    \"Use standard Markdown format for your output.\\n\\n\"\n",
    "    \n",
    "    \"Guidelines:\\n\"\n",
    "    \"- Prefer quoting code snippets using triple backticks (```) to preserve formatting.\\n\"\n",
    "    \"- If the context includes Markdown images (e.g. ![alt](url)), and the image is relevant, you may include it in the response.\\n\"\n",
    "    \"- Keep the response structured and easy to read with proper Markdown sections if needed.\\n\"\n",
    "    \"- If the answer is unknown or not present in the context, say: '我不知道。'\\n\\n\"\n",
    "\n",
    "    \"Question: {question}\\n\"\n",
    "    \"Context: {context}\"\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# LangGraph Nodes\n",
    "# ---------------------------------------------------------------------------\n",
    "async def generate_query_or_respond(state: MessagesState):\n",
    "    \"\"\"LLM decides to answer directly or call retriever tool.\"\"\"\n",
    "    response = await model.bind_tools([retriever_tool]).ainvoke(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_INSTRUCTION},\n",
    "            *state[\"messages\"],\n",
    "        ]\n",
    "    )\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "class GradeDoc(BaseModel):\n",
    "    binary_score: str = Field(description=\"Relevance score 'yes' or 'no'.\")\n",
    "\n",
    "\n",
    "async def grade_documents(state: MessagesState) -> Literal[\"generate_answer\", \"rewrite_question\"]:\n",
    "    question = state[\"messages\"][0].content  # original user question\n",
    "    ctx = state[\"messages\"][-1].content      # retriever output\n",
    "    prompt = GRADE_PROMPT.format(question=question, context=ctx)\n",
    "    result = await grader_model.with_structured_output(GradeDoc).ainvoke([\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ])\n",
    "    return \"generate_answer\" if result.binary_score.lower().startswith(\"y\") else \"rewrite_question\"\n",
    "\n",
    "\n",
    "async def rewrite_question(state: MessagesState):\n",
    "    question = state[\"messages\"][0].content\n",
    "    prompt = REWRITE_PROMPT.format(question=question)\n",
    "    resp = await model.ainvoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "    return {\"messages\": [{\"role\": \"user\", \"content\": resp.content}]}\n",
    "\n",
    "\n",
    "async def generate_answer(state: MessagesState):\n",
    "    question = state[\"messages\"][0].content\n",
    "    ctx = state[\"messages\"][-1].content\n",
    "    prompt = ANSWER_PROMPT.format(question=question, context=ctx)\n",
    "    resp = await model.ainvoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "    return {\"messages\": [resp]}\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Build graph\n",
    "# ---------------------------------------------------------------------------\n",
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"generate_query_or_respond\", generate_query_or_respond)\n",
    "workflow.add_node(\"retrieve\", ToolNode([retriever_tool]))\n",
    "workflow.add_node(\"rewrite_question\", rewrite_question)\n",
    "workflow.add_node(\"generate_answer\", generate_answer)\n",
    "\n",
    "workflow.add_edge(START, \"generate_query_or_respond\")\n",
    "workflow.add_edge(\"generate_query_or_respond\", \"retrieve\")\n",
    "workflow.add_conditional_edges(\"retrieve\", grade_documents)\n",
    "workflow.add_edge(\"generate_answer\", END)\n",
    "workflow.add_edge(\"rewrite_question\", \"generate_query_or_respond\")\n",
    "\n",
    "rag_agent = workflow.compile(name=\"rag_agent\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
